{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Linear Regression using scikit-learn"
      ],
      "metadata": {
        "id": "awIE2FfilRCB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USEUYnn6k6O_",
        "outputId": "6104ab8f-c618-4336-b4a8-2fef09a970c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n",
            "60\n",
            "Intercept is 1961.992\n",
            "Weights for carat and table features are [7820.038  -74.301]\n",
            "Predicted price is [1413.97]\n"
          ]
        }
      ],
      "source": [
        "# Import needed packages for regression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Silence warning from sklearn\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Input feature values for a sample instance\n",
        "carat = float(input())\n",
        "table = float(input())\n",
        "\n",
        "# Load the diamonds dataset\n",
        "diamonds = pd.read_csv('diamonds.csv')\n",
        "\n",
        "# Define input and output features\n",
        "X = diamonds[['carat', 'table']]\n",
        "y = diamonds['price']\n",
        "\n",
        "# Initialize a multiple linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the multiple linear regression model to the input and output features\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get estimated intercept weight\n",
        "intercept = model.intercept_\n",
        "print('Intercept is', round(intercept, 3))\n",
        "\n",
        "# Get estimated weights for carat and table features\n",
        "coefficients = model.coef_\n",
        "print('Weights for carat and table features are', np.round(coefficients, 3))\n",
        "\n",
        "# Predict the price of a diamond with the user-input carat and table values\n",
        "prediction = model.predict(np.array([[carat, table]]))\n",
        "print('Predicted price is', np.round(prediction, 2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Logistic Regression using scikit-learn"
      ],
      "metadata": {
        "id": "R-vzKzeilmWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load nbaallelo_log.csv into a dataframe\n",
        "NBA = pd.read_csv('nbaallelo_log.csv')\n",
        "\n",
        "# Create binary feature for game_result with 0 for L and 1 for W\n",
        "NBA['win'] = NBA['game_result'].apply(lambda x: 1 if x == 'W' else 0)\n",
        "\n",
        "# Store relevant columns as variables\n",
        "X = NBA[['elo_i']]\n",
        "y = NBA['win'].ravel()  # Flatten to a 1-D array\n",
        "\n",
        "# Initialize and fit the logistic model using the LogisticRegression() function\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print the weights for the fitted model\n",
        "print('w1:', model.coef_)\n",
        "\n",
        "# Print the intercept of the fitted model\n",
        "print('w0:', model.intercept_)\n",
        "\n",
        "# Find the proportion of instances correctly classified\n",
        "y_pred = model.predict(X)\n",
        "score = accuracy_score(y, y_pred)\n",
        "print(round(score, 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJmMyN50lpcC",
        "outputId": "6c1c70aa-86b6-4f06-ab9c-b4722c72cb68"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w1: [[0.00437785]]\n",
            "w0: [-6.54757518]\n",
            "0.599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Support Vector Classifier using scikit-learn"
      ],
      "metadata": {
        "id": "5mzu8H7QlrJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Load the heart dataset\n",
        "heart = pd.read_csv('heart.csv')\n",
        "\n",
        "# Input features: thalach and age\n",
        "X = heart[['thalach', 'age']]\n",
        "\n",
        "# Output feature: target\n",
        "y = heart[['target']]\n",
        "\n",
        "# Create training and testing data with 75% training data and 25% testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize a support vector classifier with C=0.2 and a maximum of 500 iterations\n",
        "SVC = LinearSVC(C=0.2, max_iter=500, random_state=123)\n",
        "\n",
        "# Fit the support vector classifier according to the training data\n",
        "SVC.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "# Evaluate model on testing data\n",
        "score = SVC.score(X_test, np.ravel(y_test))\n",
        "print(np.round(score, 3))\n",
        "\n",
        "# Print the model weights\n",
        "# w0 (intercept)\n",
        "print('w0:', np.round(SVC.intercept_, 3))\n",
        "\n",
        "# w1 and w2 (coefficients)\n",
        "print('w1 and w2:', np.round(SVC.coef_, 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_M8c3ojlt2C",
        "outputId": "fcc76358-ea5a-43d2-d208-433df29684cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.671\n",
            "w0: [0.125]\n",
            "w1 and w2: [[ 0.39  -0.084]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. k-Nearest Neighbors using scikit-learn"
      ],
      "metadata": {
        "id": "1kH8OUUvlwGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import needed packages for classification\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import packages for evaluation\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "skySurvey = pd.read_csv('SDSS.csv')\n",
        "\n",
        "# Create a new feature from u - g\n",
        "skySurvey['u_g'] = skySurvey['u'] - skySurvey['g']\n",
        "\n",
        "# Create dataframe X with features redshift and u_g\n",
        "X = skySurvey[['redshift', 'u_g']]\n",
        "\n",
        "# Create dataframe y with feature class\n",
        "y = skySurvey['class']\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "# Initialize model with k=3\n",
        "skySurveyKnn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Fit model using X_train and y_train\n",
        "skySurveyKnn.fit(X_train, y_train)\n",
        "\n",
        "# Find the predicted classes for X_test\n",
        "y_pred = skySurveyKnn.predict(X_test)\n",
        "\n",
        "# Calculate accuracy score\n",
        "score = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print accuracy score\n",
        "print('Accuracy score is ', end=\"\")\n",
        "print('%.3f' % score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrbbsFwNlw7K",
        "outputId": "6997ca5c-851b-4359-9f81-ee281ff2288e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 0.984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Naive Bayes using scikit-learn"
      ],
      "metadata": {
        "id": "SVekUDS3l4MJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "import pandas as pd\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "skySurvey = pd.read_csv('SDSS.csv')\n",
        "\n",
        "# Create a new feature from u - g\n",
        "skySurvey['u_g'] = skySurvey['u'] - skySurvey['g']\n",
        "\n",
        "# Create dataframe X with features redshift and u_g\n",
        "X = skySurvey[['redshift', 'u_g']]\n",
        "\n",
        "# Create dataframe y with feature class\n",
        "y = skySurvey['class'].ravel()  # Flatten to a 1-D array\n",
        "\n",
        "# Initialize a Gaussian naive Bayes model\n",
        "skySurveyNBModel = GaussianNB()\n",
        "\n",
        "# Fit the model\n",
        "skySurveyNBModel.fit(X, y)\n",
        "\n",
        "# Calculate the proportion of instances correctly classified\n",
        "y_pred = skySurveyNBModel.predict(X)\n",
        "score = accuracy_score(y, y_pred)\n",
        "\n",
        "# Print accuracy score\n",
        "print('Accuracy score is ', end=\"\")\n",
        "print('%.3f' % score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnbu_dill5ia",
        "outputId": "41c6e8aa-4e78-4d58-8b16-c012695e2821"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 0.989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.1. Bagging using scikit-learn"
      ],
      "metadata": {
        "id": "xRXSj1Sal8pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('msleep_clean.csv')\n",
        "\n",
        "# Create a dataframe X containing the features awake, brainwt, and bodywt, in that order\n",
        "X = df[['awake', 'brainwt', 'bodywt']]\n",
        "\n",
        "# Create a dataframe y containing sleep_rem\n",
        "y = df['sleep_rem']\n",
        "\n",
        "# Initialize and fit bagging regressor with 30 base estimators, a random state of 10, and oob_score=True\n",
        "sleepModel = BaggingRegressor(n_estimators=30, random_state=10, oob_score=True)\n",
        "sleepModel.fit(X, y)\n",
        "\n",
        "# Calculate out-of-bag accuracy\n",
        "print(np.round(sleepModel.oob_score_, 4))\n",
        "\n",
        "# Calculate predictions from out-of-bag estimate\n",
        "print(np.round(sleepModel.oob_prediction_, 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "220Sn9GEl9TB",
        "outputId": "4ff667b5-1848-4f39-cdfe-8ec1b68b704d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3144\n",
            "[3.1    2.98   0.8    1.6867 0.7167 1.8533 2.3091 2.0727 1.5231 2.1727\n",
            " 2.95   0.5375 2.9417 2.8727 0.9    0.7765 1.9818 2.5    1.8692 1.57\n",
            " 0.9692 1.1778 1.5769 2.75   2.4    2.1364 4.1727 1.6765 0.71   1.3909\n",
            " 2.13   1.9733 3.1429 3.3533 0.51   2.0077 1.4    2.0143 2.45   1.975\n",
            " 2.6    2.3    1.2    0.58   2.8222 1.9222 0.7417 1.24  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2. Random forests using scikit-learn"
      ],
      "metadata": {
        "id": "8X8OO613mGFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('mpg_clean.csv')\n",
        "\n",
        "# Create a dataframe X containing the input features\n",
        "X = df.drop(columns=['name', 'origin'])\n",
        "# Create a dataframe y containing the output feature origin\n",
        "y = df['origin']\n",
        "\n",
        "# Get user-input for n_estimators and max_features\n",
        "estimators = int(input())\n",
        "max_features = int(input())\n",
        "\n",
        "# Initialize and fit a random forest classifier with user-input parameters\n",
        "rfModel = RandomForestClassifier(n_estimators=estimators, max_features=max_features, random_state=123)\n",
        "rfModel.fit(X, y)\n",
        "\n",
        "# Calculate prediction accuracy\n",
        "score = rfModel.score(X, y)\n",
        "print(round(score, 4))\n",
        "\n",
        "# Calculate the permutation importance using the default parameters and a random state of 123\n",
        "result = permutation_importance(rfModel, X, y, random_state=123)\n",
        "\n",
        "# Variable importance table\n",
        "importance_table = pd.DataFrame(\n",
        "    data={'feature': rfModel.feature_names_in_, 'permutation importance': result.importances_mean}\n",
        ").sort_values('permutation importance', ascending=False)\n",
        "\n",
        "print(importance_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAkpjClomHJh",
        "outputId": "f96a7165-0850-4632-84ce-c775d1c327a3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "3\n",
            "0.9796\n",
            "        feature  permutation importance\n",
            "2  displacement                0.453571\n",
            "0           mpg                0.160204\n",
            "4        weight                0.133673\n",
            "3    horsepower                0.107653\n",
            "5  acceleration                0.057143\n",
            "6    model_year                0.051531\n",
            "1     cylinders                0.012245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.3. Boosting using scikit-learn"
      ],
      "metadata": {
        "id": "dauejw-SmO9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "mpg = pd.read_csv('mpg.csv')\n",
        "\n",
        "# Create a dataframe X containing cylinders, weight, and mpg\n",
        "X = mpg[['cylinders', 'weight', 'mpg']]\n",
        "# Create a dataframe y containing origin\n",
        "y = mpg['origin']\n",
        "\n",
        "# Get user-input for learning rate\n",
        "lr = float(input())\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
        "\n",
        "# Initialize and fit an adaptive boosting classifier with the user-input learning rate\n",
        "adaBoostModel = AdaBoostClassifier(learning_rate=lr, random_state=123)\n",
        "adaBoostModel.fit(X_train, y_train)\n",
        "\n",
        "# Initialize and fit a gradient boosting classifier with the user-input learning rate\n",
        "gradientBoostModel = GradientBoostingClassifier(learning_rate=lr, random_state=123)\n",
        "gradientBoostModel.fit(X_train, y_train)\n",
        "\n",
        "# Calculate the prediction accuracy for the adaptive boosting classifier\n",
        "adaBoostScore = adaBoostModel.score(X_test, y_test)\n",
        "print(round(adaBoostScore, 4))\n",
        "\n",
        "# Calculate the prediction accuracy for the gradient boosting classifier\n",
        "gradientBoostScore = gradientBoostModel.score(X_test, y_test)\n",
        "print(round(gradientBoostScore, 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8PaploAmP6q",
        "outputId": "fcbda9f7-ca5c-4e64-d7f5-31f4f34b7128"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6\n",
            "0.6417\n",
            "0.6417\n"
          ]
        }
      ]
    }
  ]
}